{
 "metadata": {
  "name": "Skin Detection"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cv\n",
      "import cv2\n",
      "from PIL import Image\n",
      " \n",
      "# load the c1lassifiers\n",
      "haarFace = cv.Load('haarcascade_frontalface_default.xml')\n",
      "haarEyes = cv.Load('haarcascade_eye.xml')\n",
      "\n",
      "def skinColour(im, pointA, pointB):\n",
      "    r = []\n",
      "    g = []\n",
      "    b = []\n",
      "\n",
      "    for i in range(int(pointA[0]), int(pointB[0])):\n",
      "        for j in range(int(pointA[1]),int(pointB[1])):\n",
      "            r.append(im[i,j,0])\n",
      "            g.append(im[i,j,1])\n",
      "            b.append(im[i,j,2])\n",
      "\n",
      "    rmean = np.mean(r)\n",
      "    gmean = np.mean(g)\n",
      "    bmean = np.mean(b)\n",
      "    rstd = np.std(r)\n",
      "    gstd = np.std(g)\n",
      "    bstd = np.std(b)\n",
      "    \n",
      "    means = (rmean, gmean, bmean)\n",
      "    stds = (rstd, gstd, bstd)\n",
      "    \n",
      "    return means, stds\n",
      "        \n",
      "\n",
      "def faceFind(frame, detectedEyes, detectedFace):\n",
      "    num_eyes = 0\n",
      "    eyes_in_face = []\n",
      "    actual_eyes = []\n",
      " \n",
      "    if detectedFace:\n",
      "        for face in detectedFace:\n",
      "     \n",
      "            #only take eyes in face\n",
      "            for eye in detectedEyes:\n",
      "                if eye[0][0] >= face[0][0] and eye[0][1] >= face[0][1] and (eye[0][0] + eye[0][2]) <= (face[0][0]+face[0][2]) and (eye[0][1] + eye[0][3]) <= (face[0][1]+face[0][3]):\n",
      "                    eyes_in_face.append(eye)\n",
      "                    num_eyes += 1\n",
      "     \n",
      "            #If more than two eyes are found, find the pair of eyes closest in size, ignore other eyes\n",
      "            if len(eyes_in_face) > 2:\n",
      "                diffs = []\n",
      "                index_1 = []\n",
      "                index_2 = []\n",
      "                for e in range(0, len(eyes_in_face) - 1):\n",
      "                    for x in range(e+1, len(eyes_in_face)):\n",
      "                        diff = abs(eyes_in_face[e][0][2] - eyes_in_face[x][0][2])\n",
      "                        index_1.append(e)\n",
      "                        index_2.append(x)\n",
      "                        diffs.append(diff)\n",
      "                i = diffs.index(min(diffs))\n",
      "                actual_eyes.append(eyes_in_face[index_1[i]])\n",
      "                actual_eyes.append(eyes_in_face[index_2[i]])\n",
      "            else:\n",
      "                actual_eyes = eyes_in_face\n",
      "     \n",
      "            if num_eyes > 0:\n",
      "                user_face = face\n",
      "                user_eyes = actual_eyes\n",
      "                break\n",
      "       \n",
      "            eyes_in_face = []\n",
      "            actual_eyes = []\n",
      "        if user_eyes:\n",
      "            eye = user_eyes[0]\n",
      "            pointA = (eye[0][0] + (0.25*eye[0][2]), eye[0][1] + eye[0][3])\n",
      "            pointB = (eye[0][0] + (0.75*eye[0][2]), eye[0][1] + (1.5*eye[0][3]))\n",
      "            #cv.Rectangle(frame,pointA,pointB, cv.RGB(155, 55, 200),2)\n",
      "            means, stds = skinColour(frame, pointA, pointB)\n",
      "        else:\n",
      "            means = 0\n",
      "            stds = 0\n",
      "    else:\n",
      "            means = 0\n",
      "            stds = 0\n",
      "    return means, stds\n",
      "    \n",
      "\n",
      "cam = cv2.VideoCapture(0)\n",
      "\n",
      "winName = \"Skin Detection\"\n",
      "cv2.namedWindow(winName, cv2.CV_WINDOW_AUTOSIZE)\n",
      "\n",
      "means = 0\n",
      "stds = 0\n",
      "delta = 2\n",
      "\n",
      "while not means:\n",
      "    frame = cv2.cvtColor(cam.read()[1], cv2.COLOR_RGB2GRAY)\n",
      "    # running the classifiers\n",
      "    storage = cv.CreateMemStorage()\n",
      "    detectedFace = cv.HaarDetectObjects(cv.fromarray(frame), haarFace, storage)\n",
      "    detectedEyes = cv.HaarDetectObjects(cv.fromarray(frame), haarEyes, storage)\n",
      "    \n",
      "    means, stds = faceFind(frame, detectedEyes, detectedFace)\n",
      "\n",
      "low = (means[0]-stds[0]*2*delta, means[1]-stds[1]*2*delta, means[2]-stds[2]*2*delta)\n",
      "high = (means[0]+stds[0]*2*delta, means[1]+stds[1]*2*delta, means[2]+stds[2]*2*delta)\n",
      "    \n",
      "while True:\n",
      "    ret, frame = cam.read()\n",
      "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
      "    frame = inRange(frame, low, high)\n",
      "    contours, hierarchy = cv2.findContours(frame,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
      "    if len(contours):\n",
      "        mergeContour = contours[0]\n",
      "        for i in contours[1:]:\n",
      "             mergeContour = np.concatenate((mergeContour,i))\n",
      "    \n",
      "        hull = cv2.convexHull(mergeContour)\n",
      "        imgray = cv2.cvtColor(frame,cv.CV_BGR2GRAY)\n",
      "        cv2.drawContours(imgray,[hull],-1,(255,0,0),2)\n",
      "    cv2.imshow( winName, imgray)\n",
      "    \n",
      "    key = cv2.waitKey(10)\n",
      "    if key == 27:\n",
      "        cv2.destroyWindow(winName)\n",
      "        break\n",
      "\n",
      "    \n",
      "\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "index 498 is out of bounds for axis 0 with size 480",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-1-e66e32d5e1b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mdetectedEyes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHaarDetectObjects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhaarEyes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfaceFind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetectedEyes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetectedFace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0mlow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-1-e66e32d5e1b8>\u001b[0m in \u001b[0;36mfaceFind\u001b[0;34m(frame, detectedEyes, detectedFace)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mpointB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meye\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;31m#cv.Rectangle(frame,pointA,pointB, cv.RGB(155, 55, 200),2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskinColour\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpointA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpointB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-1-e66e32d5e1b8>\u001b[0m in \u001b[0;36mskinColour\u001b[0;34m(im, pointA, pointB)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpointA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpointB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpointA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpointB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIndexError\u001b[0m: index 498 is out of bounds for axis 0 with size 480"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}